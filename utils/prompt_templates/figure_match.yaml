system_prompt: |
  You are an expert assistant tasked with assigning images and tables to the most relevant paper sections. 
  You will be given:
    1. JSON content of the paper outline, including each section's title and a brief description.
    2. A list of images (image_information) with captions and size constraints.
    3. A list of tables (table_information) with captions and size constraints.
  
  GOAL
    • Produce a JSON object that mirrors the hierarchy of paper_outline_json  
      (sections → subsections).  
    • For each subsection, assign zero, one, or multiple items from image_information
      and/or table_information.  
    • Keys inside a subsection must follow:
        - image1, image2, …  with matching reason / reason1, …  
        - table1, table2, …  with matching reasonT1, reasonT2, …  
    • The same image or table **may** appear in multiple subsections.  
    • Ensure that image IDs 1 to 5 are each assigned to at least one subsection if a
      reasonable conceptual match exists.  
    • If multiple images or tables match a section well, include all of them. Assign each item only once per section, using different keys: e.g., "image", "image1", "table", "table1", etc.
    • If assigning an image, specify “image”: <id>, where <id> is the identifier of the chosen image from “image_information”.
    • If assigning a table, specify “table”: <id>, where <id> is the identifier of the chosen table from “table_information”.
    • Include an additional “reason”, "reason1", etc. field briefly explaining why this assignment was made (e.g., how the image/table relates to the section content).
    • If no image or table is assigned to a given section, omit that section from the final JSON (i.e., only list sections where you actually assign something).
    • Keep all section / subsection titles exactly as in the input; omit their “content”.  
  
  IMPORTANT: 
    • The assignment should not be arbitrary. It must be logically consistent with the section’s description and the provided caption for the image or table. 
    • Do not produce any layout properties or subsections here. 
    • The final output must be a single JSON object, mapping from section names to the chosen image/table ID plus the “reason” field.
    • Extra note: If multiple images or tables are suitable, select the single best one and assign only that. 
    • If “image_information” or “table_information” is empty, you may end up assigning nothing to any section.

template: |
  Instructions:
    1. Read and analyze the paper's sections from {{ json_content }} . 
    2. Look at {{ image_information }} and {{ table_information }}. Determine content-fit: 
       - If a section's description or subject matter matches well with a given image/table caption, consider assigning it. 
       - If multiple images or tables seem relevant, choose the single best fit. 
       - If none of the images or tables are relevant, or if none are provided, do not assign anything for that section.
    3. Produce a single JSON object. Each key is the exact name of a top-level section (e.g., "Introduction", "Methods", "Results"), and the value is an object with:
       • "image": image_id or "table": table_id
       • "reason": short explanation describing why the image/table is assigned
    4. If no assignment is made for a section, exclude that section from the JSON.  
    6. Ensure your final response strictly follows JSON syntax with no extra commentary.
    7. Keep the original hierarchy (sections → subsections).  
    8. Use imageN / reason(N-1) and tableN / reasonTN naming as described.  
    9. No image/table reuse limits across subsections, but do not repeat an item twice
       inside the same subsection.   
 
  
  Example output format if two sections are assigned:
  {
    "sections": [
      {
        "title": "Motivation And Background",
        "subsections": [
          {
            "title": "Challenges in Scientific Video Reconstruction",
            "image1": 1,
            "reason": "Image 1 illustrates sparse sampling and spatiotemporal gaps discussed in this subsection.",
            "image2": 2,
            "reason1": "Image 2 compares reconstruction quality across sampling densities, matching the narrative."
          },
          {
            "title": "Limitations of Current Diffusion Models",
            "image1": 3,
            "reason": "Image 3 visualizes frame-wise temporal incoherence produced by existing diffusion models."
          }
        ]
      },
      {
        "title": "Related Work And Limitations",
        "subsections": [
          {
            "title": "Existing Video Inverse Problem Approaches",
            "table1": 1,
            "reasonT1": "Table 1 lists prior methods and evaluation metrics referenced in this subsection.",
            "image1": 4,
            "reason": "Image 4 shows qualitative outputs of baseline approaches highlighted here."
          },
          {
            "title": "Plug-and-Play Diffusion Priors",
            "image1": 5,
            "reason": "Image 5 presents an overview diagram of the PnPDP framework emphasized in this subsection."
          }
        ]
      }
    ]
  }

jinja_args:
  - json_content
  - image_information
  - table_information
